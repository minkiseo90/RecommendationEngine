{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.models.word2vec as w2v\n",
    "import multiprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"D:/songdata.csv\", header = 0)\n",
    "songs.head()\n",
    "songs = songs[songs.artist != 'Lata Mangeshkar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_corpus = []\n",
    "for song in songs['text']:\n",
    "    words = song.lower().split()\n",
    "    text_corpus.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Look', 'at', 'her', 'face', ',', 'it', \"'s\", 'a', 'wonderful', 'face', 'And', 'it', 'means', 'something', 'special', 'to', 'me', 'Look', 'at', 'the', 'way', 'that', 'she', 'smiles', 'when', 'she', 'sees', 'me', 'How', 'lucky', 'can', 'one', 'fellow', 'be', '?', 'She', \"'s\", 'just', 'my', 'kind', 'of', 'girl', ',', 'she', 'makes', 'me', 'feel', 'fine', 'Who', 'could', 'ever', 'believe', 'that', 'she', 'could', 'be', 'mine', '?', 'She', \"'s\", 'just', 'my', 'kind', 'of', 'girl', ',', 'without', 'her', 'I', \"'m\", 'blue', 'And', 'if', 'she', 'ever', 'leaves', 'me', 'what', 'could', 'I', 'do', ',', 'what', 'could', 'I', 'do', '?', 'And', 'when', 'we', 'go', 'for', 'a', 'walk', 'in', 'the', 'park', 'And', 'she', 'holds', 'me', 'and', 'squeezes', 'my', 'hand', 'We', \"'ll\", 'go', 'on', 'walking', 'for', 'hours', 'and', 'talking', 'About', 'all', 'the', 'things', 'that', 'we', 'plan', 'She', \"'s\", 'just', 'my', 'kind', 'of', 'girl', ',', 'she', 'makes', 'me', 'feel', 'fine', 'Who', 'could', 'ever', 'believe', 'that', 'she', 'could', 'be', 'mine', '?', 'She', \"'s\", 'just', 'my', 'kind', 'of', 'girl', ',', 'without', 'her', 'I', \"'m\", 'blue', 'And', 'if', 'she', 'ever', 'leaves', 'me', 'what', 'could', 'I', 'do', ',', 'what', 'could', 'I', 'do', '?'], ['Take', 'it', 'easy', 'with', 'me', ',', 'please', 'Touch', 'me', 'gently', 'like', 'a', 'summer', 'evening', 'breeze', 'Take', 'your', 'time', ',', 'make', 'it', 'slow', 'Andante', ',', 'Andante', 'Just', 'let', 'the', 'feeling', 'grow', 'Make', 'your', 'fingers', 'soft', 'and', 'light', 'Let', 'your', 'body', 'be', 'the', 'velvet', 'of', 'the', 'night', 'Touch', 'my', 'soul', ',', 'you', 'know', 'how', 'Andante', ',', 'Andante', 'Go', 'slowly', 'with', 'me', 'now', 'I', \"'m\", 'your', 'music', '(', 'I', 'am', 'your', 'music', 'and', 'I', 'am', 'your', 'song', ')', 'I', \"'m\", 'your', 'song', '(', 'I', 'am', 'your', 'music', 'and', 'I', 'am', 'your', 'song', ')', 'Play', 'me', 'time', 'and', 'time', 'again', 'and', 'make', 'me', 'strong', '(', 'Play', 'me', 'again', \"'cause\", 'you', \"'re\", 'making', 'me', 'strong', ')', 'Make', 'me', 'sing', ',', 'make', 'me', 'sound', '(', 'You', 'make', 'me', 'sing', 'and', 'you', 'make', 'me', ')', 'Andante', ',', 'Andante', 'Tread', 'lightly', 'on', 'my', 'ground', 'Andante', ',', 'Andante', 'Oh', 'please', 'do', \"n't\", 'let', 'me', 'down', 'There', \"'s\", 'a', 'shimmer', 'in', 'your', 'eyes', 'Like', 'the', 'feeling', 'of', 'a', 'thousand', 'butterflies', 'Please', 'do', \"n't\", 'talk', ',', 'go', 'on', ',', 'play', 'Andante', ',', 'Andante', 'And', 'let', 'me', 'float', 'away', 'I', \"'m\", 'your', 'music', '(', 'I', 'am', 'your', 'music', 'and', 'I', 'am', 'your', 'song', ')', 'I', \"'m\", 'your', 'song', '(', 'I', 'am', 'your', 'music', 'and', 'I', 'am', 'your', 'song', ')', 'Play', 'me', 'time', 'and', 'time', 'again', 'and', 'make', 'me', 'strong', '(', 'Play', 'me', 'again', \"'cause\", 'you', \"'re\", 'making', 'me', 'strong', ')', 'Make', 'me', 'sing', ',', 'make', 'me', 'sound', '(', 'You', 'make', 'me', 'sing', 'and', 'you', 'make', 'me', ')', 'Andante', ',', 'Andante', 'Tread', 'lightly', 'on', 'my', 'ground', 'Andante', ',', 'Andante', 'Oh', 'please', 'do', \"n't\", 'let', 'me', 'down', 'Make', 'me', 'sing', ',', 'make', 'me', 'sound', '(', 'You', 'make', 'me', 'sing', 'and', 'you', 'make', 'me', ')', 'Andante', ',', 'Andante', 'Tread', 'lightly', 'on', 'my', 'ground', 'Andante', ',', 'Andante', 'Oh', 'please', 'do', \"n't\", 'let', 'me', 'down', 'Andante', ',', 'Andante', 'Oh', 'please', 'do', \"n't\", 'let', 'me', 'down'], ['I', \"'ll\", 'never', 'know', 'why', 'I', 'had', 'to', 'go', 'Why', 'I', 'had', 'to', 'put', 'up', 'such', 'a', 'lousy', 'rotten', 'show', 'Boy', ',', 'I', 'was', 'tough', ',', 'packing', 'all', 'my', 'stuff', 'Saying', 'I', 'do', \"n't\", 'need', 'you', 'anymore', ',', 'I', \"'ve\", 'had', 'enough', 'And', 'now', ',', 'look', 'at', 'me', 'standing', 'here', 'again', \"'cause\", 'I', 'found', 'out', 'that', 'Ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'my', 'life', 'is', 'here', 'Got', 'ta', 'have', 'you', 'near', 'As', 'good', 'as', 'new', ',', 'my', 'love', 'for', 'you', 'And', 'keeping', 'it', 'that', 'way', 'is', 'my', 'intention', 'As', 'good', 'as', 'new', 'and', 'growing', 'too', 'Yes', ',', 'I', 'think', 'it', \"'s\", 'taking', 'on', 'a', 'new', 'dimension', 'It', \"'s\", 'as', 'good', 'as', 'new', ',', 'my', 'love', 'for', 'you', 'Just', 'like', 'it', 'used', 'to', 'be', 'and', 'even', 'better', 'As', 'good', 'as', 'new', ',', 'thank', 'God', 'it', \"'s\", 'true', 'Darling', ',', 'we', 'were', 'always', 'meant', 'to', 'stay', 'together', 'Feel', 'like', 'a', 'creep', ',', 'never', 'felt', 'so', 'cheap', 'Never', 'had', 'a', 'notion', 'that', 'my', 'love', 'could', 'be', 'so', 'deep', 'How', 'could', 'I', 'make', 'such', 'a', 'dumb', 'mistake', 'Now', 'I', 'know', 'I', \"'m\", 'not', 'entitled', 'to', 'another', 'break', 'But', 'please', ',', 'baby', ',', 'I', 'beg', 'you', 'to', 'forgive', \"'cause\", 'I', 'found', 'out', 'that', 'Ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'ma', 'my', 'life', 'is', 'here', 'Got', 'ta', 'get', 'you', 'near', 'I', 'thought', 'that', 'our', 'love', 'was', 'at', 'an', 'end', 'but', 'here', 'I', 'am', 'again', 'As', 'good', 'as', 'new', ',', 'my', 'love', 'for', 'you', 'And', 'keeping', 'it', 'that', 'way', 'is', 'my', 'intention', 'As', 'good', 'as', 'new', 'and', 'growing', 'too', 'Yes', ',', 'I', 'think', 'it', \"'s\", 'taking', 'on', 'a', 'new', 'dimension', 'It', \"'s\", 'as', 'good', 'as', 'new', ',', 'my', 'love', 'for', 'you', 'Just', 'like', 'it', 'used', 'to', 'be', 'and', 'even', 'better', 'As', 'good', 'as', 'new', ',', 'thank', 'God', 'it', \"'s\", 'true', 'Darling', ',', 'we', 'were', 'always', 'meant', 'to', 'stay', 'together', 'Yes', 'the', 'love', 'I', 'have', 'for', 'you', 'feels', 'as', 'good', 'as', 'new', 'Darling', ',', 'we', 'were', 'always', 'meant', 'to', 'stay', 'together']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57618"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_corpus[0:3])\n",
    "len(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57618\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality of the resulting word vectors.\n",
    "#more dimensions, more computationally expensive to train\n",
    "#but also more accurate\n",
    "#more dimensions = more generalized\n",
    "num_features = 50\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 1\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "#more workers, faster we train\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "\n",
    "downsampling = 1e-1\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "#random number generator\n",
    "#deterministic, good for debugging\n",
    "seed = 1\n",
    "\n",
    "songs2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")\n",
    "\n",
    "songs2vec.build_vocab(text_corpus)\n",
    "print (len(text_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text_corpus = []\n",
    "for song in songs['text']:\n",
    "    sentence = sent_tokenize(song)\n",
    "    text_corpus.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Look at her face, it's a wonderful face  \\nAnd it means something special to me  \\nLook at the way that she smiles when she sees me  \\nHow lucky can one fellow be?\",\n",
       "  \"She's just my kind of girl, she makes me feel fine  \\nWho could ever believe that she could be mine?\",\n",
       "  \"She's just my kind of girl, without her I'm blue  \\nAnd if she ever leaves me what could I do, what could I do?\",\n",
       "  \"And when we go for a walk in the park  \\nAnd she holds me and squeezes my hand  \\nWe'll go on walking for hours and talking  \\nAbout all the things that we plan  \\n  \\nShe's just my kind of girl, she makes me feel fine  \\nWho could ever believe that she could be mine?\",\n",
       "  \"She's just my kind of girl, without her I'm blue  \\nAnd if she ever leaves me what could I do, what could I do?\"],\n",
       " [\"Take it easy with me, please  \\nTouch me gently like a summer evening breeze  \\nTake your time, make it slow  \\nAndante, Andante  \\nJust let the feeling grow  \\n  \\nMake your fingers soft and light  \\nLet your body be the velvet of the night  \\nTouch my soul, you know how  \\nAndante, Andante  \\nGo slowly with me now  \\n  \\nI'm your music  \\n(I am your music and I am your song)  \\nI'm your song  \\n(I am your music and I am your song)  \\nPlay me time and time again and make me strong  \\n(Play me again 'cause you're making me strong)  \\nMake me sing, make me sound  \\n(You make me sing and you make me)  \\nAndante, Andante  \\nTread lightly on my ground  \\nAndante, Andante  \\nOh please don't let me down  \\n  \\nThere's a shimmer in your eyes  \\nLike the feeling of a thousand butterflies  \\nPlease don't talk, go on, play  \\nAndante, Andante  \\nAnd let me float away  \\n  \\nI'm your music  \\n(I am your music and I am your song)  \\nI'm your song  \\n(I am your music and I am your song)  \\nPlay me time and time again and make me strong  \\n(Play me again 'cause you're making me strong)  \\nMake me sing, make me sound  \\n(You make me sing and you make me)  \\nAndante, Andante  \\nTread lightly on my ground  \\nAndante, Andante  \\nOh please don't let me down  \\n  \\nMake me sing, make me sound  \\n(You make me sing and you make me)  \\nAndante, Andante  \\nTread lightly on my ground  \\nAndante, Andante  \\nOh please don't let me down  \\nAndante, Andante  \\nOh please don't let me down\"],\n",
       " [\"I'll never know why I had to go  \\nWhy I had to put up such a lousy rotten show  \\nBoy, I was tough, packing all my stuff  \\nSaying I don't need you anymore, I've had enough  \\nAnd now, look at me standing here again 'cause I found out that  \\nMa ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \\nGotta have you near  \\n  \\nAs good as new, my love for you  \\nAnd keeping it that way is my intention  \\nAs good as new and growing too  \\nYes, I think it's taking on a new dimension  \\nIt's as good as new, my love for you  \\nJust like it used to be and even better  \\nAs good as new, thank God it's true  \\nDarling, we were always meant to stay together  \\n  \\nFeel like a creep, never felt so cheap  \\nNever had a notion that my love could be so deep  \\nHow could I make such a dumb mistake  \\nNow I know I'm not entitled to another break  \\nBut please, baby, I beg you to forgive 'cause I found out that  \\nMa ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \\nGotta get you near  \\n  \\nI thought that our love was at an end but here I am again  \\n  \\nAs good as new, my love for you  \\nAnd keeping it that way is my intention  \\nAs good as new and growing too  \\nYes, I think it's taking on a new dimension  \\nIt's as good as new, my love for you  \\nJust like it used to be and even better  \\nAs good as new, thank God it's true  \\nDarling, we were always meant to stay together  \\n  \\nYes the love I have for you feels as good as new  \\nDarling, we were always meant to stay together\"]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_corpus[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Look', 'at', 'her', 'face', ',', 'it', \"'s\", 'a', 'wonderful', 'face', 'And', 'it', 'means', 'something', 'special', 'to', 'me', 'Look', 'at', 'the', 'way', 'that', 'she', 'smiles', 'when', 'she', 'sees', 'me', 'How', 'lucky', 'can', 'one', 'fellow', 'be', '?', 'She', \"'s\", 'just', 'my', 'kind', 'of', 'girl', ',', 'she', 'makes', 'me', 'feel', 'fine', 'Who', 'could', 'ever', 'believe', 'that', 'she', 'could', 'be', 'mine', '?', 'She', \"'s\", 'just', 'my', 'kind', 'of', 'girl', ',', 'without', 'her', 'I', \"'m\", 'blue', 'And', 'if', 'she', 'ever', 'leaves', 'me', 'what', 'could', 'I', 'do', ',', 'what', 'could', 'I', 'do', '?', 'And', 'when', 'we', 'go', 'for', 'a', 'walk', 'in', 'the', 'park', 'And', 'she', 'holds', 'me', 'and', 'squeezes', 'my', 'hand', 'We', \"'ll\", 'go', 'on', 'walking', 'for', 'hours', 'and', 'talking', 'About', 'all', 'the', 'things', 'that', 'we', 'plan', 'She', \"'s\", 'just', 'my', 'kind', 'of', 'girl', ',', 'she', 'makes', 'me', 'feel', 'fine', 'Who', 'could', 'ever', 'believe', 'that', 'she', 'could', 'be', 'mine', '?', 'She', \"'s\", 'just', 'my', 'kind', 'of', 'girl', ',', 'without', 'her', 'I', \"'m\", 'blue', 'And', 'if', 'she', 'ever', 'leaves', 'me', 'what', 'could', 'I', 'do', ',', 'what', 'could', 'I', 'do', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text_corpus = []\n",
    "for song in songs['text']:\n",
    "    words = word_tokenize(song)\n",
    "    text_corpus.append(words)\n",
    "\n",
    "print(text_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Look', 'face', ',', \"'s\", 'wonderful', 'face', 'And', 'means', 'something', 'special', 'Look', 'way', 'smiles', 'sees', 'How', 'lucky', 'one', 'fellow', '?', 'She', \"'s\", 'kind', 'girl', ',', 'makes', 'feel', 'fine', 'Who', 'could', 'ever', 'believe', 'could', 'mine', '?', 'She', \"'s\", 'kind', 'girl', ',', 'without', 'I', \"'m\", 'blue', 'And', 'ever', 'leaves', 'could', 'I', ',', 'could', 'I', '?', 'And', 'go', 'walk', 'park', 'And', 'holds', 'squeezes', 'hand', 'We', \"'ll\", 'go', 'walking', 'hours', 'talking', 'About', 'things', 'plan', 'She', \"'s\", 'kind', 'girl', ',', 'makes', 'feel', 'fine', 'Who', 'could', 'ever', 'believe', 'could', 'mine', '?', 'She', \"'s\", 'kind', 'girl', ',', 'without', 'I', \"'m\", 'blue', 'And', 'ever', 'leaves', 'could', 'I', ',', 'could', 'I', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "english_stops = set(stopwords.words('english'))\n",
    "\n",
    "txt_corpus_nostopwords = []\n",
    "for song in text_corpus:\n",
    "    word = [word for word in song if word not in english_stops]\n",
    "    txt_corpus_nostopwords.append(word)\n",
    "    \n",
    "print(txt_corpus_nostopwords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Look', 'face', ',', \"'s\", 'wonderful', 'face', 'And', 'mean', 'something', 'special', 'Look', 'way', 'smile', 'see', 'How', 'lucky', 'one', 'fellow', '?', 'She', \"'s\", 'kind', 'girl', ',', 'make', 'feel', 'fine', 'Who', 'could', 'ever', 'believe', 'could', 'mine', '?', 'She', \"'s\", 'kind', 'girl', ',', 'without', 'I', \"'m\", 'blue', 'And', 'ever', 'leaf', 'could', 'I', ',', 'could', 'I', '?', 'And', 'go', 'walk', 'park', 'And', 'hold', 'squeeze', 'hand', 'We', \"'ll\", 'go', 'walking', 'hour', 'talking', 'About', 'thing', 'plan', 'She', \"'s\", 'kind', 'girl', ',', 'make', 'feel', 'fine', 'Who', 'could', 'ever', 'believe', 'could', 'mine', '?', 'She', \"'s\", 'kind', 'girl', ',', 'without', 'I', \"'m\", 'blue', 'And', 'ever', 'leaf', 'could', 'I', ',', 'could', 'I', '?']\n"
     ]
    }
   ],
   "source": [
    "txt_corpus_lemmas = []\n",
    "for song in txt_corpus_nostopwords:\n",
    "    txt_corpus_lemma = []    \n",
    "    for song_word in song:\n",
    "        word = lemmatizer.lemmatize(song_word, pos = 'n')\n",
    "        txt_corpus_lemma.append(word)\n",
    "        \n",
    "    txt_corpus_lemmas.append(txt_corpus_lemma)\n",
    "    \n",
    "print(txt_corpus_lemmas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
